{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Name: Abd-el-rahman Zaglool\n",
    "\n",
    "###### ID: 5107746\n",
    "\n",
    "###### Project: News classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the project, I'll collect the news from The New York Times webpage. Articles will be retrieved from 8 different sections:\n",
    "1. Business\n",
    "2. Science\n",
    "3. Health\n",
    "4. Sports\n",
    "5. Arts\n",
    "6. Style \n",
    "7. Food\n",
    "8. Travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the necessary packages\n",
    "\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The New York Times offer a wide range of handy APIs. One of them is 'Times Wire API' that allows to retrieve the real-time feed of NYT published articles.\n",
    "\n",
    "To fetch articles from the 'Times Wire API' I'll create a helper function named scrape_articles(). \n",
    "\n",
    "The function will take as inputs the desired news' section and the number of articles to retrieve ('limit' parameter).\n",
    " \n",
    "The function returns the response as a JSON object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_articles(section, limit):\n",
    "  requestUrl = requestUrl = 'https://api.nytimes.com/svc/news/v3/content/all/'+section+'.json?limit='+str(limit)+'&api-key=X5IOvJkmFhSRsE7jrZHfMM25hEATDJpS'\n",
    "  requestHeaders = {\n",
    "    \"Accept\": \"application/json\"\n",
    "  }\n",
    "\n",
    "  response = requests.get(requestUrl, headers=requestHeaders).json()\n",
    "\n",
    "  return response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll also define a second helper function in order to extract the necessary fields ('title', 'abstract' and 'section' of the article) from the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_articles(response):\n",
    "        articles = []\n",
    "        docs = response['results']\n",
    "        for doc in docs:\n",
    "                filteredDoc = {}\n",
    "                filteredDoc['title'] = doc['title']\n",
    "                filteredDoc['abstract'] = doc['abstract']\n",
    "                filteredDoc['section'] = doc['section']\n",
    "                articles.append(filteredDoc)\n",
    "\n",
    "        return articles        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll use the two functions defined above to iterate articles retrieval and fields extraction over all of the 8 sections.\n",
    "\n",
    "The result will be a list of lists (8) where each list contains articles from one section only. \n",
    "\n",
    "The articles are stored as dictionaries with three keys: 'title', 'abstract' and 'section'.\n",
    "\n",
    "From each section I've collected at most 500 articles. Number of articles collected may change among sections depending on the feed at the time of code execution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = ['business', 'science', 'health', 'sports', 'arts', 'style', 'food', 'travel']\n",
    "limit = 500\n",
    "news = []\n",
    "\n",
    "for section in sections:\n",
    "\n",
    "    response = scrape_articles(section, limit)\n",
    "    section_articles = retrieve_articles(response)\n",
    "    news.append(section_articles)\n",
    "    time.sleep(12)    \n",
    "\n",
    "# time elapsed 1m 57s    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll store the retrieved news in a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Iterate over each list of dictionaries\n",
    "for sublist in news:\n",
    "    # Create a temporary DataFrame for each list of dictionaries\n",
    "    temp_df = pd.DataFrame(sublist)\n",
    "    \n",
    "    # Concatenate the temporary DataFrame with the main DataFrame\n",
    "    df = pd.concat([df, temp_df], ignore_index=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Ukraine War Changed This Company Forever</td>\n",
       "      <td>Nokian Tyres of Finland made 80 percent of its...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In Business, ‘Flat’ Structures Rarely Work. Is...</td>\n",
       "      <td>Companies that have rejected hierarchies have ...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Federal Judge Limits Biden Officials’ Contacts...</td>\n",
       "      <td>The order came in a lawsuit filed by the attor...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meta Loses Appeal on How It Harvests Data in G...</td>\n",
       "      <td>The ruling by the European Court of Justice cl...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Corporate Landscaping Lets Its Hair Down</td>\n",
       "      <td>More companies are eschewing manicured grass i...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991</th>\n",
       "      <td>A Caribbean Island’s Audacious Tourism Experiment</td>\n",
       "      <td>To step onto Montserrat’s volcanic beaches, 21...</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2992</th>\n",
       "      <td>Quarantine and Travel: Strict Penalties, Rare ...</td>\n",
       "      <td>As quarantine requirements for travelers have ...</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2993</th>\n",
       "      <td>Traveling the World, While Looking Over Her Sh...</td>\n",
       "      <td>The number of women traveling the world solo i...</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994</th>\n",
       "      <td>Luxury Comes to Expedition Cruising</td>\n",
       "      <td>New small ships built for adventure are also o...</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>What Sara Blakely, Spanx Founder, Can’t Travel...</td>\n",
       "      <td>Her list includes Samsonite luggage, Bose head...</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2996 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0          The Ukraine War Changed This Company Forever   \n",
       "1     In Business, ‘Flat’ Structures Rarely Work. Is...   \n",
       "2     Federal Judge Limits Biden Officials’ Contacts...   \n",
       "3     Meta Loses Appeal on How It Harvests Data in G...   \n",
       "4              Corporate Landscaping Lets Its Hair Down   \n",
       "...                                                 ...   \n",
       "2991  A Caribbean Island’s Audacious Tourism Experiment   \n",
       "2992  Quarantine and Travel: Strict Penalties, Rare ...   \n",
       "2993  Traveling the World, While Looking Over Her Sh...   \n",
       "2994                Luxury Comes to Expedition Cruising   \n",
       "2995  What Sara Blakely, Spanx Founder, Can’t Travel...   \n",
       "\n",
       "                                               abstract   section  \n",
       "0     Nokian Tyres of Finland made 80 percent of its...  Business  \n",
       "1     Companies that have rejected hierarchies have ...  Business  \n",
       "2     The order came in a lawsuit filed by the attor...  Business  \n",
       "3     The ruling by the European Court of Justice cl...  Business  \n",
       "4     More companies are eschewing manicured grass i...  Business  \n",
       "...                                                 ...       ...  \n",
       "2991  To step onto Montserrat’s volcanic beaches, 21...    Travel  \n",
       "2992  As quarantine requirements for travelers have ...    Travel  \n",
       "2993  The number of women traveling the world solo i...    Travel  \n",
       "2994  New small ships built for adventure are also o...    Travel  \n",
       "2995  Her list includes Samsonite luggage, Bose head...    Travel  \n",
       "\n",
       "[2996 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "section\n",
       "Business    500\n",
       "Sports      500\n",
       "Arts        500\n",
       "Style       500\n",
       "Food        375\n",
       "Science     299\n",
       "Health      175\n",
       "Travel      147\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualizing number of articles retrieved by section\n",
    "df.section.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping rows with NaN on both title and abstract:\n",
    "df = df.drop(index= df[(df['title'].isna()) & df['abstract'].isna()].index)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Ukraine War Changed This Company Forever :...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In Business, ‘Flat’ Structures Rarely Work. Is...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Federal Judge Limits Biden Officials’ Contacts...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meta Loses Appeal on How It Harvests Data in G...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Corporate Landscaping Lets Its Hair Down : Mor...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991</th>\n",
       "      <td>A Caribbean Island’s Audacious Tourism Experim...</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2992</th>\n",
       "      <td>Quarantine and Travel: Strict Penalties, Rare ...</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2993</th>\n",
       "      <td>Traveling the World, While Looking Over Her Sh...</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994</th>\n",
       "      <td>Luxury Comes to Expedition Cruising : New smal...</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>What Sara Blakely, Spanx Founder, Can’t Travel...</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2996 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                article   section\n",
       "0     The Ukraine War Changed This Company Forever :...  Business\n",
       "1     In Business, ‘Flat’ Structures Rarely Work. Is...  Business\n",
       "2     Federal Judge Limits Biden Officials’ Contacts...  Business\n",
       "3     Meta Loses Appeal on How It Harvests Data in G...  Business\n",
       "4     Corporate Landscaping Lets Its Hair Down : Mor...  Business\n",
       "...                                                 ...       ...\n",
       "2991  A Caribbean Island’s Audacious Tourism Experim...    Travel\n",
       "2992  Quarantine and Travel: Strict Penalties, Rare ...    Travel\n",
       "2993  Traveling the World, While Looking Over Her Sh...    Travel\n",
       "2994  Luxury Comes to Expedition Cruising : New smal...    Travel\n",
       "2995  What Sara Blakely, Spanx Founder, Can’t Travel...    Travel\n",
       "\n",
       "[2996 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenating title and abstract into the same 'article' column\n",
    "# Some rows have NA in title, others have NA in abstract so I have to handle the different cases \n",
    "\n",
    "df.loc[df[df['abstract'].isna()].index, 'title'] = df[df['abstract'].isna()]['title'].values #NA in abstract \n",
    "df.loc[df[(df['title'].notnull()) & (df['abstract'].notnull())].index, 'title'] = df[(df['title'].notnull()) & (df['abstract'].notnull())]['title'].values + ' : ' + df[(df['title'].notnull()) & (df['abstract'].notnull())]['abstract'].values #no NAs\n",
    "df.loc[df[df['title'].isna()].index, 'title'] = df[df['title'].isna()]['abstract'].values #NA in title\n",
    "df.rename(columns={'title' : 'article'}, inplace=True)\n",
    "df.drop(columns= df.columns[1], axis=1, inplace=True)\n",
    "df    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll set up the necessary components for text preprocessing tasks. \n",
    "\n",
    "Preprocessing involve text tokenization, stop words removal, part-of-speech mapping and lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) #retrieving english stop words list\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+') #initializing tokenizer\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Maps the input word's POS tag to the appropriate WordNet POS tag\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer() #initializing lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing a for loop to preprocess each article of the news dataframe\n",
    "\n",
    "nrows= df.shape[0]\n",
    "corpus = []\n",
    "\n",
    "for i in range(0, nrows):\n",
    "    globals()['article%s' % i] = df.iloc[i,0]\n",
    "\n",
    "    globals()['word_tokens%s' % i] = tokenizer.tokenize(globals()['article%s' % i]) #tokenization by word\n",
    "    globals()['filtered_sentence%s' % i] = [w.lower() for w in globals()['word_tokens%s' % i] if not w.lower() in stop_words]  # insert only words that aren't present in stop_words. In lowercase\n",
    "\n",
    "    globals()['filtered_sentence_lemmatized%s' % i] = [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in globals()['filtered_sentence%s' % i]] #lemmatize the worlds in globals()['filtered_sentence%s' % i]\n",
    "    globals()['filtered_sentence_lemmatized%s' % i] = ' '.join(globals()['filtered_sentence_lemmatized%s' % i])\n",
    "    corpus.append(globals()['filtered_sentence_lemmatized%s' % i])\n",
    "\n",
    "# time elapsed: 5m 14s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll save then the processed articles as a new column in my DataFrame.\n",
    "\n",
    "In addition, I'll factorize the sections (i.e. assign a different number to each section). The factorized_section column will be my target variable in the news classification problem.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>section</th>\n",
       "      <th>processed_article</th>\n",
       "      <th>factorized_section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Ukraine War Changed This Company Forever :...</td>\n",
       "      <td>Business</td>\n",
       "      <td>ukraine war change company forever nokian tyre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In Business, ‘Flat’ Structures Rarely Work. Is...</td>\n",
       "      <td>Business</td>\n",
       "      <td>business flat structure rarely work solution c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Federal Judge Limits Biden Officials’ Contacts...</td>\n",
       "      <td>Business</td>\n",
       "      <td>federal judge limit biden official contact soc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meta Loses Appeal on How It Harvests Data in G...</td>\n",
       "      <td>Business</td>\n",
       "      <td>meta loses appeal harvest data germany ruling ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Corporate Landscaping Lets Its Hair Down : Mor...</td>\n",
       "      <td>Business</td>\n",
       "      <td>corporate landscape let hair company eschew ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991</th>\n",
       "      <td>A Caribbean Island’s Audacious Tourism Experim...</td>\n",
       "      <td>Travel</td>\n",
       "      <td>caribbean island audacious tourism experiment ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2992</th>\n",
       "      <td>Quarantine and Travel: Strict Penalties, Rare ...</td>\n",
       "      <td>Travel</td>\n",
       "      <td>quarantine travel strict penalty rare enforcem...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2993</th>\n",
       "      <td>Traveling the World, While Looking Over Her Sh...</td>\n",
       "      <td>Travel</td>\n",
       "      <td>travel world look shoulder number woman travel...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994</th>\n",
       "      <td>Luxury Comes to Expedition Cruising : New smal...</td>\n",
       "      <td>Travel</td>\n",
       "      <td>luxury come expedition cruise new small ship b...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>What Sara Blakely, Spanx Founder, Can’t Travel...</td>\n",
       "      <td>Travel</td>\n",
       "      <td>sara blakely spanx founder travel without list...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2996 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                article   section  \\\n",
       "0     The Ukraine War Changed This Company Forever :...  Business   \n",
       "1     In Business, ‘Flat’ Structures Rarely Work. Is...  Business   \n",
       "2     Federal Judge Limits Biden Officials’ Contacts...  Business   \n",
       "3     Meta Loses Appeal on How It Harvests Data in G...  Business   \n",
       "4     Corporate Landscaping Lets Its Hair Down : Mor...  Business   \n",
       "...                                                 ...       ...   \n",
       "2991  A Caribbean Island’s Audacious Tourism Experim...    Travel   \n",
       "2992  Quarantine and Travel: Strict Penalties, Rare ...    Travel   \n",
       "2993  Traveling the World, While Looking Over Her Sh...    Travel   \n",
       "2994  Luxury Comes to Expedition Cruising : New smal...    Travel   \n",
       "2995  What Sara Blakely, Spanx Founder, Can’t Travel...    Travel   \n",
       "\n",
       "                                      processed_article  factorized_section  \n",
       "0     ukraine war change company forever nokian tyre...                   0  \n",
       "1     business flat structure rarely work solution c...                   0  \n",
       "2     federal judge limit biden official contact soc...                   0  \n",
       "3     meta loses appeal harvest data germany ruling ...                   0  \n",
       "4     corporate landscape let hair company eschew ma...                   0  \n",
       "...                                                 ...                 ...  \n",
       "2991  caribbean island audacious tourism experiment ...                   7  \n",
       "2992  quarantine travel strict penalty rare enforcem...                   7  \n",
       "2993  travel world look shoulder number woman travel...                   7  \n",
       "2994  luxury come expedition cruise new small ship b...                   7  \n",
       "2995  sara blakely spanx founder travel without list...                   7  \n",
       "\n",
       "[2996 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['processed_article'] = corpus\n",
    "df['factorized_section'] = df['section'].factorize()[0]\n",
    "df.dropna(inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>section</th>\n",
       "      <th>factorized_section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>Science</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>Health</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>Sports</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474</th>\n",
       "      <td>Arts</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>Style</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>Food</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2849</th>\n",
       "      <td>Travel</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       section  factorized_section\n",
       "0     Business                   0\n",
       "500    Science                   1\n",
       "799     Health                   2\n",
       "974     Sports                   3\n",
       "1474      Arts                   4\n",
       "1974     Style                   5\n",
       "2474      Food                   6\n",
       "2849    Travel                   7"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the factorization legend\n",
    "df[['section', 'factorized_section']].drop_duplicates().sort_values('factorized_section')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be fed to the classification model, the processed articles must be converted into a numerical representation. In particular, with  the help Scikit-learn's CountVectorizer class I'll represent the corpus as a sparse matrix with n rows = n processed articles and n columns = n unique words in the corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:,2].values\n",
    "y = df.factorized_section.values\n",
    "\n",
    "# Init CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "# Fit to the corpus\n",
    "x = cv.fit_transform(x).toarray()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I only need to split the data in train (80% of data) and test (the remaining 20%) portions, and I'll be ready to call the classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42, shuffle = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To classify the articles I chose a basic Logistic Regression since it offers a good trade-off between performance and complexity (i.e. computational expense). Given that news classification problem involves multiple labels, I'll resort to OneVsRestClassifier() class. \n",
    "\n",
    "OneVsRest takes a binary classifier (the Logistic Regression) and wraps it to handle multiclass classification problems by decomposing them into multiple binary classification tasks.\n",
    "\n",
    "To evaluate the predictive power of the model, considering the equal importance of all labels, I relied on the accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Basic Logistic Regression: 77.5 %\n"
     ]
    }
   ],
   "source": [
    "mdl = LogisticRegression(random_state=42)\n",
    "\n",
    "oneVsRest = OneVsRestClassifier(mdl)\n",
    "\n",
    "oneVsRest.fit(x_train, y_train)\n",
    "\n",
    "y_pred = oneVsRest.predict(x_test)\n",
    "\n",
    "# Performance\n",
    "accuracy = round(accuracy_score(y_test, y_pred)*100, 2)\n",
    "print(f'Accuracy Score of Basic Logistic Regression: {accuracy} %')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Accuracy score measures the proportion of correctly predicted labels compared to the total number of samples. On average, our Logistic regression correctly predicts the section of 8 articles out of 10! That's already a great result, which can be further enhanced by, for example, employing some hyperparameter fine-tuning..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
